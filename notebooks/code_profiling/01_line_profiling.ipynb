{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3918ca",
   "metadata": {},
   "source": [
    "# Profiling Code Run Times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4887b9a2-433f-49dd-b305-216040e10cfe",
   "metadata": {},
   "source": [
    "## 1. Snippet Performance\n",
    "\n",
    "When we want to compare the performance of small pieces of code to perform single tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fe9e72-229d-4c24-9d5d-27b91b7929e0",
   "metadata": {},
   "source": [
    "### 1.1 Using `time`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0643b4e-93ba-4a85-a50d-6d1753da31e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e560d7b8-bda0-4f85-b1a7-f366c77673e4",
   "metadata": {},
   "source": [
    "We have some integer IDs and the frequency of their occurrence within a dataset. We want to remove any integers with a frequency above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d5133-b5e5-44ed-8547-23be573b81af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ids(p=.00005, size=1_000_000):\n",
    "    \"\"\"Generate an array of random integers with a geometric frequency distribution.\n",
    "    \n",
    "    Args:\n",
    "        p: See `p` for `numpy.random.geometric`.\n",
    "        size: Length of generated array.\n",
    "        \n",
    "    Returns:\n",
    "        Array of integers.\n",
    "    \"\"\"\n",
    "    idx = np.random.geometric(p, size) - 1\n",
    "    x = range(np.max(idx))\n",
    "    choices = np.random.choice(x, idx.shape[0])\n",
    "    print(\"Number of unique IDs: {}\".format(np.unique(idx).shape[0]))\n",
    "    return choices[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cabf178-6c8a-44fb-a1e5-a2b10947b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = generate_ids()\n",
    "unique_ids_counter = Counter(unique_ids)\n",
    "print(\"Most common IDs:\", unique_ids_counter.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d3938a-ab4c-4d5a-b913-e4c6de2ece8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(\n",
    "    unique_ids_counter.values(), \n",
    "    bins=100, \n",
    "    cumulative=True, \n",
    "    density=\"normed\", \n",
    "    histtype=\"step\", \n",
    "    linewidth=2\n",
    ")\n",
    "ax.set_xlabel(\"ID Count\")\n",
    "ax.set_ylabel(\"Normalised Cumulative Frequency\")\n",
    "ax.set_xlim(0, max(unique_ids_counter.values()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9493e11-8f31-4467-99d4-113e9b9b6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "def filter_freq_map_filter(ids_counter, min_frequency=10):\n",
    "    \"\"\"Filters items from a `Counter` with frequencies below `min_frequency`. \n",
    "    \n",
    "    Gets items from counter after applying `filter` operation.\n",
    "    \"\"\"\n",
    "    return list(map(itemgetter(0), filter(lambda x: x[1] >= min_frequency, ids_counter.items())))\n",
    "\n",
    "def filter_freq_iterate(ids_counter, min_frequency=10):\n",
    "    \"\"\"Filters items from a `Counter` with frequencies below `min_frequency`.\n",
    "    \n",
    "    Iterates through items in counter and drops keys with frequencies below\n",
    "    `min_frequency`.\n",
    "    \"\"\"\n",
    "    return [k for k, v in ids_counter.items() if v >= min_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b694621-b275-4bd1-83fc-5b2b38feb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_function(function, **kwargs):\n",
    "    start = time()\n",
    "    function(**kwargs)\n",
    "    end = time()\n",
    "    total = end - start\n",
    "    print(f\"Took {total} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adafbb9-a1a2-4888-af24-02da5d6fd2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using map and filter...\")\n",
    "time_function(filter_freq_map_filter, **{'ids_counter': unique_ids_counter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63444fe-9275-4613-a999-0d51768e9e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Using list comprehension...\")\n",
    "time_function(filter_freq_iterate, **{'ids_counter': unique_ids_counter})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b918f2-4422-4fe2-a7df-087244e39638",
   "metadata": {},
   "source": [
    "### 1.2 Using `timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386bd4c-2efb-4059-bbbd-329c53ff5885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c203a0e-6797-4670-95b4-2d13b540ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = timeit.Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c79e369-ddb9-4fce-8eef-4a41fb77b3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_i = timeit.repeat(\n",
    "    stmt='filter_freq_iterate(unique_ids_counter)', \n",
    "    setup=\"from __main__ import filter_freq_iterate, unique_ids_counter\",\n",
    "    repeat=5,\n",
    "    number=100\n",
    ")\n",
    "sorted(t_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861bf21e-453b-480d-a320-601b60e3a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mf = timeit.repeat(\n",
    "    stmt='filter_freq_map_filter(unique_ids_counter)', \n",
    "    setup=\"from __main__ import filter_freq_map_filter, unique_ids_counter\",\n",
    "    repeat=5,\n",
    "    number=100\n",
    ")\n",
    "sorted(t_mf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6fbbc4-98eb-4a08-a20c-93bdcd1690a5",
   "metadata": {},
   "source": [
    "### 1.3 Using Magic `time` and `timeit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcea56",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = filter_freq_map_filter(unique_ids_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72941c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = filter_freq_map_filter(unique_ids_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a28f21-7787-4736-b306-e997be1c6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = filter_freq_iterate(unique_ids_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f3bec-f9dd-4c78-8f6b-e75295aa70b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "_ = filter_freq_iterate(unique_ids_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba97f45-28ab-4ac8-8ba3-4b93ad18f06b",
   "metadata": {},
   "source": [
    "### 1.4 Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce33484-fb2c-4954-9529-fb961b761f36",
   "metadata": {},
   "source": [
    "Write two or more different simple functions to complete one of the tasks below and time how long they take to execute on some dummy data. Were the results what you expected?\n",
    "\n",
    "- Removing punctuation from a string\n",
    "- Fetching items from a list based on their index location\n",
    "- Finding the index of an item in a list\n",
    "- Calculating the Jaccard similarity between sets of sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c394c271",
   "metadata": {},
   "source": [
    "### 1.5 Realistic Timing and Estimating Run times\n",
    "\n",
    "When we process large datasets in a pipeline, we often need to estimate how long it might take. Long running processes are fragile to interruptions, slow down our work and can cost a lot more to run in terms of energy and money. \n",
    "\n",
    "Before running a piece of code on a full set of data, it's useful to prototype on a smaller sample and estimate the running time for the full set. This is good practice anyway, as you don't want to run a long pipeline on all of your data only to find you made a mistake that results in erroneous ouputs.\n",
    "\n",
    "When testing your code on a sample to estimate run times or to compare performance, bear in mind:\n",
    "\n",
    "- üìà Run times are not always linear. For example, applying a function to larger batches of data and/or processing data with higher dimensions may have a quadratic or exponential effect on total running time. If you're unsure, test a few different parameters.\n",
    "- üèó When testing how long it takes your code to run on a sample it can be tempting to just run it on the first N rows. In some cases however, the order of your data will have an impact. For example, you may have text data that increases in length with the number of rows, which would lead you to underestimate the total run time.\n",
    "- üîã Some code involves overheads such as building indices, loading lookups or preparing data for parallel processing. Ideally these overheads are minimal but in some cases their runtimes can be comparable to the rest of your code. It's important to find the right trade off between invoking these overheads and the total amount of time your code takes to run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403df695",
   "metadata": {},
   "source": [
    "## 2. Line Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cbbdba",
   "metadata": {},
   "source": [
    "Usually, our code is more complex than a few snippets or one liners, particularly in long data processing or modelling pipelines, which are typically formed from multiple functions of varying complexity. If you time your code while prototyping, you might find that it takes too long to run and seek ways to speed it up. `line_profiler` helps you to identify which parts of your code are taking the longest and to think about strategies for speeding them up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15282ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install line_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e841d7cf",
   "metadata": {},
   "source": [
    "### 2.1 Filtering IDs... again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721b6db",
   "metadata": {},
   "source": [
    "In our previous example, we filtered the IDs whose frequencies had already been counted.\n",
    "\n",
    "```python\n",
    "unique_ids_counter = Counter(unique_ids)\n",
    "filtered = filter_freq_iterate(unique_ids_counter)\n",
    "\n",
    "```\n",
    "\n",
    "But, what if we don't recieve counts, but the raw IDs instead? In many real situations, this construction time will also need to be taken into account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b260a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_id_freqs_iter(ids, min_frequency=10):\n",
    "    \"\"\"Filters items from a list with frequencies below `min_frequency`.\n",
    "    \n",
    "    Iterates through items in counter and drops keys with frequencies below\n",
    "    `min_frequency`.\n",
    "    \"\"\"\n",
    "    counts = Counter(ids)\n",
    "    return [k for k, v in counts.items() if v >= min_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3cead8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = filter_id_freqs_iter(unique_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6aa1ac",
   "metadata": {},
   "source": [
    "This is much slower!\n",
    "\n",
    "The only thing we have changed is that we're now counting the IDs inside the function. We would expect this to be the cause of the slow down, but let's take a look to see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a20d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d02d35",
   "metadata": {},
   "source": [
    "The line profiler extension allows us to profile code by timing how long it takes to run each line within a function.\n",
    "\n",
    "```python\n",
    "%lprun \\            # Use the line profiler magic function\n",
    "-f my_function \\    # Pass in the name of the function you want to profile\n",
    "my_function(a, b)   # Run the function on some inputs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f937f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun \\\n",
    "-f filter_id_freqs_iter \\\n",
    "filter_id_freqs_iter(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272492ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_id_freqs_np(ids, min_frequency=10):\n",
    "    \"\"\"Filters items from a list with frequencies below `min_frequency`\n",
    "    \n",
    "    Uses `np.unique` to calculate the counts of each item and then \n",
    "    subsets those above the threshold frequency from the unique values.\n",
    "    \"\"\"\n",
    "    vals, counts = np.unique(ids, return_counts=True)\n",
    "    return vals[counts >= min_frequency]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44aebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = filter_id_freqs_np(unique_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e5a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f filter_id_freqs_np filter_id_freqs_np(unique_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad22b48",
   "metadata": {},
   "source": [
    "### 2.2 Vectorisation sensation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a42292",
   "metadata": {},
   "source": [
    "Note: This example is taken from [Mortada Mehyar's blog](https://mortada.net/easily-profile-python-code-in-jupyter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5d2e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "origin = {'lat': 34, 'lon': -120}\n",
    "\n",
    "def generate_random_walk():\n",
    "    np.random.seed(1)\n",
    "    n = 100000\n",
    "    changes = np.random.randn(n, 2) / 30\n",
    "    changes[0] = [0, 0]\n",
    "    trace = pd.DataFrame.from_records(changes, columns=['lat', 'lon']).cumsum()\n",
    "    trace['lat'] += origin['lat']\n",
    "    trace['lon'] += origin['lon']\n",
    "    return trace\n",
    "\n",
    "trace = generate_random_walk()\n",
    "\n",
    "plt.plot(trace['lat'], trace['lon'])\n",
    "plt.scatter(origin['lat'], origin['lon'], color='C1', s=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0703cdaa",
   "metadata": {},
   "source": [
    "**Haversine Distance**\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Illustration_of_great-circle_distance.svg/1920px-Illustration_of_great-circle_distance.svg.png\" alt=\"Haversine\" width=\"200\"/>\n",
    "\n",
    "[Source: Wikipedia](https://en.wikipedia.org/wiki/Great-circle_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"Calculate the great circle distance between two points \n",
    "    on the earth (specified in lat/lon)\n",
    "    \"\"\"\n",
    "    # convert to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    earth_radius = 6367\n",
    "    distance_km = earth_radius * c\n",
    "    return distance_km\n",
    "\n",
    "def get_distances(trace, origin):\n",
    "    distances = {}\n",
    "    for i in trace.index:\n",
    "        distances[i] = haversine(\n",
    "            trace['lat'].loc[i], trace['lon'].loc[i], origin['lat'], origin['lon']\n",
    "        )\n",
    "    distances = pd.Series(distances)\n",
    "    return distances\n",
    "\n",
    "def get_farthest(trace, origin):\n",
    "    distance = get_distances(trace, origin)\n",
    "    max_idx = distance.argmax()\n",
    "    return trace.loc[max_idx], distance.loc[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896804bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_farthest(trace, origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c174a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f get_farthest get_farthest(trace, origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f971a5",
   "metadata": {},
   "source": [
    "You can also use the line profiler to profile specific calls made within the function you are profiling. We do this by passing in the sub-function name under the `-f` flag. Here we will profile `get_distances` as it runs when we call `get_farthest` with our arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0527c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f get_distances get_farthest(trace, origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0a5553",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_vectorized(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth. Note that lat1/lon1/lat2/lon2 can either be\n",
    "    scalars or numpy arrays.\n",
    "    \"\"\"\n",
    "    # convert to radians \n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a)) \n",
    "    earth_radius = 6367\n",
    "    distance_km = earth_radius * c\n",
    "    return distance_km\n",
    "\n",
    "def get_distances_vectorized(trace, origin):\n",
    "    distances = haversine_vectorized(\n",
    "        trace['lat'], trace['lon'], origin['lat'], origin['lon']\n",
    "    )\n",
    "    return distances\n",
    "\n",
    "def get_farthest_vectorized(trace, origin):\n",
    "    distance = get_distances_vectorized(trace, origin)\n",
    "    max_idx = distance.argmax()\n",
    "    return trace.loc[max_idx], distance.loc[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058e39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f haversine_vectorized get_farthest_vectorized(trace, origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6896707",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "get_farthest_vectorized(trace, origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbd0d9",
   "metadata": {},
   "source": [
    "### 2.3 Exercise: Text Preprocessing\n",
    "\n",
    "Preprocessing text is often a first step before analysis or modelling. There are few off-the-shelf text preprocessing pipelines that can meet every need, so we often find ourselves writing a set of functions to do the job for our specific task.\n",
    "\n",
    "Here, we're going to examine a function that does some basic text cleaning on film reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d154d8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy datasets\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5b7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from datasets import list_datasets, load_dataset\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "rotten = load_dataset('rotten_tomatoes')\n",
    "rotten = rotten['train']['text'];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23aedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotten[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98424773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_string(tokens, max_length):\n",
    "    \"\"\"Convert a list of strings into a single space-separated string\n",
    "    truncated to `max_length`.\n",
    "    \"\"\"\n",
    "    text_string = ''\n",
    "    n = 0\n",
    "    for token in tokens:\n",
    "        n += 1\n",
    "        if n < max_length:\n",
    "            text_string = text_string + token + ' '\n",
    "        elif n == max_length:\n",
    "            text_string = text_string + token\n",
    "\n",
    "    return text_string\n",
    "    \n",
    "def make_spacy_docs(texts):\n",
    "    \"\"\"Generates spacy doc from a string.\"\"\"\n",
    "    for text in texts:\n",
    "        yield nlp(text)\n",
    "\n",
    "\n",
    "def clean_texts(texts, max_length=10):\n",
    "    \"\"\"Cleans and truncates a set of texts. Removes punctuation, stop\n",
    "    words and numbers. Only returns the first `max_length` tokens.\n",
    "    \"\"\"\n",
    "    docs = make_spacy_docs(texts)\n",
    "    \n",
    "    clean_texts = []\n",
    "    for doc in docs:\n",
    "        clean_tokens = []\n",
    "        for token in doc:\n",
    "            if token.is_punct:\n",
    "                continue\n",
    "            if token.is_stop:\n",
    "                continue\n",
    "            if token.is_digit:\n",
    "                continue\n",
    "            \n",
    "            clean_tokens.append(token.text)\n",
    "\n",
    "        clean_string = tokens_to_string(clean_tokens, max_length)\n",
    "        clean_texts.append(clean_texts)\n",
    "\n",
    "    return clean_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f652cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_ = clean_texts(rotten[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6b294",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f clean_texts clean_texts(rotten[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b75fb0b",
   "metadata": {},
   "source": [
    "What are the bottlenecks in this code?\n",
    "\n",
    "Hint: There is one big one, but you could squeeze even more performance from quite a few places."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcae2e33",
   "metadata": {},
   "source": [
    "#### Exercise\n",
    "Speed up the text cleaning pipeline above using line profiler to help diagnose the bottlenecks.\n",
    "\n",
    "Hints:\n",
    "- Read the docs!\n",
    "- There are many ways to solve this problem, but this notebook might not have all of the building blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b45d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your text cleaning pipeline here:\n",
    "\n",
    "def clean_texts_faster(texts, max_length):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb89df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# time your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6337be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun # profile your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f6417d",
   "metadata": {},
   "source": [
    "## 3. Future topics?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc94d1a",
   "metadata": {},
   "source": [
    "Discuss methods for speeding up your code.\n",
    "- Caching results of functions that you might want to use again using [`lru_cache`](https://docs.python.org/3/library/functools.html#functools.lru_cache) üóÉ\n",
    "- Try out Cython üêâ\n",
    "- Taking advantage of hardware but running code in parallel or on a GPU when you can't get any more speed out of your code or the gains would be huge üí™"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a8b0f7",
   "metadata": {},
   "source": [
    "## 4. [Draft] Make a Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49071ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = make_blobs(1_000, centers=20, random_state=42)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(blobs[:, 0], blobs[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdc5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_knn(points, k):\n",
    "    \"\"\"\"\"\"\n",
    "    pairwise_dists = pairwise_distances(points, metric='euclidean')\n",
    "    knn = []\n",
    "    for dists in pairwise_dists:\n",
    "        knn_arg = np.argsort(dists)[1: k + 1]\n",
    "        knn.append(knn_arg)\n",
    "    return knn\n",
    "\n",
    "def create_edgelist(knn):\n",
    "    edges = []\n",
    "    for s, targets in enumerate(knn):\n",
    "        for t in targets:\n",
    "            edges.append(sorted([s, t]))\n",
    "    return edges\n",
    "\n",
    "def calculate_dists():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be36415",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = get_knn(blobs, 5)\n",
    "edges = create_edgelist(knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "profiling",
   "language": "python",
   "name": "profiling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
