{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395daaf6",
   "metadata": {},
   "source": [
    "*Hello again!* ðŸ‘‹\n",
    "\n",
    "This notebook is the <u>third</u> part of a **tutorial** on how to  **collect data from Twitter API v2 using Python** ðŸ¤“\n",
    "\n",
    "This notebook contains a series of exercises that will help you get confortable with collecting Twitter data using the recent search endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25260b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010828a2",
   "metadata": {},
   "source": [
    "01. Take a look at the following dictionaries.\n",
    "\n",
    "rules_1 = [\n",
    "    \n",
    "    {\"value\": '(\"heat pump\" OR \"heat pumps\") -is:retweet lang:en'},\n",
    "\n",
    "    {\"value\": '(\"gas boiler\" OR \"gas boilers\") -is:retweet lang:en'},\n",
    "\n",
    "]\n",
    "\n",
    "and \n",
    "\n",
    "rules_2 = [\n",
    "\n",
    "    {\"value\": '(\"heat pump\" OR \"heat pumps\" OR \"gas boiler\" OR \"gas boilers\") -is:retweet lang:en'},\n",
    "\n",
    "]\n",
    "\n",
    "Do we collect the exact same tweets from rules_1 and rules_2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfd06f",
   "metadata": {},
   "source": [
    "*Your answer:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a045d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8908afd1",
   "metadata": {},
   "source": [
    "02. Taking the rules defined below, collect data including:\n",
    "- tweet fields: tweet id, tweet text, author id, tweet creation date and time, context annotations, entities, geo, public metrics, source\n",
    "- user fields: user id, name, username, date and time user created the account, description, location, if user is verified or not, public metrics\n",
    "- place fields: place id, country, country_code, country name, country full name, geo and place_type\n",
    "\n",
    "\n",
    "*Helpful links:*\n",
    "- [Tweet fields](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet)\n",
    "- [User fields](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user)\n",
    "- [Place fields](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1951d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collect_and_process_search_data import *\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "{\"value\": '(\"heat pump\" OR \"heat pumps\") -is:retweet lang:en', \"tag\":\"exercise_2\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the ... by the fields you want to collect\n",
    "query_parameters = {\n",
    "    \"tweet.fields\": \"...\",\n",
    "    \"user.fields\": \"...\",\n",
    "    \"place.fields\": \"...\",\n",
    "    \"expansions\": \"...\",\n",
    "    \"max_results\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce01e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you just want to check if you defined the rules and query_parameters correctly, and that your code is working\n",
    "headers = request_headers(bearer_token)\n",
    "query_parameters[\"query\"] = rules[0][\"value\"]\n",
    "json_response = connect_to_endpoint(endpoint_url, headers, query_parameters)\n",
    "json_response\n",
    "\n",
    "# if you want to collect the data uncomment the line below and comment the ones above\n",
    "#collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392b5604",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex2 = pd.read_pickle(\"tweets_exercise_2.pkl\")\n",
    "users_ex2 = pd.read_pickle(\"users_exercise_2.pkl\")\n",
    "places_ex2 = pd.read_pickle(\"places_exercise_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3929e17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d7eb222",
   "metadata": {},
   "source": [
    "03. Using the same query parameters you defined above, change your rules to so that the data you collect does not contain heatpump nor heatpumps hashtags.\n",
    "\n",
    "*Helpful links:*\n",
    "- Take a look at the list of operators [here](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ec14dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this list to account for the hashtags\n",
    "rules = [\n",
    "{\"value\": '(\"heat pump\" OR \"heat pumps\") -is:retweet lang:en', \"tag\":\"exercise_3\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00adc44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy your answer from previous exercise\n",
    "query_parameters = {\n",
    "    \"tweet.fields\": \"...\",\n",
    "    \"user.fields\": \"...\",\n",
    "    \"place.fields\": \"...\",\n",
    "    \"expansions\": \"...\",\n",
    "    \"max_results\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab6283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you just want to check if you defined the rules and query_parameters correctly, and that your code is working\n",
    "headers = request_headers(bearer_token)\n",
    "query_parameters[\"query\"] = rules[0][\"value\"]\n",
    "json_response = connect_to_endpoint(endpoint_url, headers, query_parameters)\n",
    "json_response\n",
    "\n",
    "# if you want to collect the data uncomment the line below and comment the ones above\n",
    "#collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0eaac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex3 = pd.read_pickle(\"tweets_exercise_3.pkl\")\n",
    "users_ex3 = pd.read_pickle(\"users_exercise_3.pkl\")\n",
    "places_ex3 = pd.read_pickle(\"places_exercise_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12694a48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143dc683",
   "metadata": {},
   "source": [
    "04. Change **rules** and **query_parms** below to collect data from Twitter satisfying the following requirements:\n",
    "- mentioning **ChatGPT** but *not mentioning* programming, refactoring or code;\n",
    "- no retweets;\n",
    "- written in english;\n",
    "- from verified authors;\n",
    "- posted between the 12th of January 2023 at 2pm (UK time) and 12th of January 2023 at 3pm (UK time);\n",
    "- 100 results per call to the API;\n",
    "- tweet fields, user fields and place fields as per exercise 2.\n",
    "\n",
    "\n",
    "*Helpful links:*\n",
    "- Take a look at the list of operators [here](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list)\n",
    "- To know more about start and end times parameters [check this page](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a838921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your rules according to the above requirements\n",
    "rules = [\n",
    "    {\"value\": '...', \"tag\":\"exercise_4\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy your query parameters from exercise 2 and change them to account for the above requirements\n",
    "query_parameters = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae55856",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex4 = pd.read_pickle(\"tweets_exercise_4.pkl\")\n",
    "users_ex4 = pd.read_pickle(\"users_exercise_4.pkl\")\n",
    "places_ex4 = pd.read_pickle(\"places_exercise_4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91fa43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2068a567",
   "metadata": {},
   "source": [
    "05. Check the *id* of the first tweet you collected in the previous exercise (which corresponds to the latest tweet). Change query_parameters dictionary to only collect tweets posted after that one (*hint:* make use of the since_id query parameter)\n",
    "\n",
    "\n",
    "*Helpful links:*\n",
    "- Take a look at the list of operators [here](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list)\n",
    "- To know more about since_id parameter [check this page](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent) or [this page](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/paginate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf307bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baca04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy rules you defined in previous exercise (tag to exercise 5)\n",
    "rules = [\n",
    "    {\"value\": '', \"tag\":\"exercise_5\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf766a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy parameters you defined in previous exercise and alter them to account for the requirements of this exercise\n",
    "query_parameters = {\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f072613",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3110b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex5 = pd.read_pickle(\"tweets_exercise_5.pkl\")\n",
    "users_ex5 = pd.read_pickle(\"users_exercise_5.pkl\")\n",
    "places_ex5 = pd.read_pickle(\"places_exercise_5.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collect_twitter_data",
   "language": "python",
   "name": "collect_twitter_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
