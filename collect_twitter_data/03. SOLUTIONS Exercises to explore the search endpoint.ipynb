{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395daaf6",
   "metadata": {},
   "source": [
    "# SOLUTIONS NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce25260b",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010828a2",
   "metadata": {},
   "source": [
    "01. Take a look at the following dictionaries.\n",
    "\n",
    "rules_1 = [\n",
    "    \n",
    "    {\"value\": '(\"heat pump\" OR \"heat pumps\") -is:retweet lang:en'},\n",
    "\n",
    "    {\"value\": '(\"gas boiler\" OR \"gas boilers\") -is:retweet lang:en'},\n",
    "\n",
    "]\n",
    "\n",
    "and \n",
    "\n",
    "rules_2 = [\n",
    "\n",
    "    {\"value\": '(\"heat pump\" OR \"heat pumps\" OR \"gas boiler\" OR \"gas boilers\") -is:retweet lang:en'},\n",
    "\n",
    "]\n",
    "\n",
    "Do we collect the exact same tweets from rules_1 and rules_2?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bfd06f",
   "metadata": {},
   "source": [
    "*Your answer:* We collect the exact same tweets, but we might collect them twice with rules_1 if they match both rules in rules_1. If we know that might be the case and we can have them all as one rule (if it does not surpass the maximum length allowed) then that's preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a045d76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8908afd1",
   "metadata": {},
   "source": [
    "02. Taking the rules defined below, collect data including:\n",
    "- tweet fields: tweet id, tweet text, author id, tweet creation date and time, context annotations, entities, geo, public metrics, source\n",
    "- user fields: user id, name, username, date and time user created the account, description, location, if user is verified or not, public metrics\n",
    "- place fields: place id, country, country_code, country name, country full name, geo and place_type\n",
    "\n",
    "\n",
    "*Helpful links:*\n",
    "- [Tweet fields](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet)\n",
    "- [User fields](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/user)\n",
    "- [Place fields](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f532236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collect_and_process_search_data import *\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031e1149",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "{\"value\": '(\"heat pump\" OR \"heat pumps\") -is:retweet lang:en', \"tag\":\"exercise_2\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6436f43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_parameters = {\n",
    "    \"tweet.fields\": \"id,text,author_id,created_at,context_annotations,entities,geo,public_metrics,source\",\n",
    "    \"user.fields\": \"id,name,username,created_at,description,location,verified,public_metrics\",\n",
    "    \"place.fields\": \"id,country,country_code,name,full_name,geo,place_type\",\n",
    "    \"expansions\": \"author_id,geo.place_id\",\n",
    "    \"max_results\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3f9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = os.environ.get(\"BEARER_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7441b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61576873",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex2 = pd.read_pickle(\"tweets_exercise_2.pkl\")\n",
    "users_ex2 = pd.read_pickle(\"users_exercise_2.pkl\")\n",
    "places_ex2 = pd.read_pickle(\"places_exercise_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c35153",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1073d28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_ex2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37e1efc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba45dec5",
   "metadata": {},
   "source": [
    "03. Using the same query parameters you defined above, change your rules to so that the data you collect does not contain heatpump nor heatpumps hashtags.\n",
    "\n",
    "*Helpful links:*\n",
    "- Take a look at the list of operators [here](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611ea987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this list to account for the hashtags\n",
    "rules = [\n",
    "{\"value\": '(\"heat pump\" OR \"heat pumps\") -(#heatpump OR #heatpump) -is:retweet lang:en', \"tag\":\"exercise_3\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f6f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy your answer from previous exercise\n",
    "query_parameters = {\n",
    "    \"tweet.fields\": \"id,text,author_id,created_at,context_annotations,entities,geo,public_metrics,source\",\n",
    "    \"user.fields\": \"id,name,username,created_at,description,location,verified,public_metrics\",\n",
    "    \"place.fields\": \"id,country,country_code,name,full_name,geo,place_type\",\n",
    "    \"expansions\": \"author_id,geo.place_id\",\n",
    "    \"max_results\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f8d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f75c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex3 = pd.read_pickle(\"tweets_exercise_3.pkl\")\n",
    "users_ex3 = pd.read_pickle(\"users_exercise_3.pkl\")\n",
    "places_ex3 = pd.read_pickle(\"places_exercise_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3da905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143dc683",
   "metadata": {},
   "source": [
    "04. Change **rules** and **query_parms** below to collect data from Twitter satisfying the following requirements:\n",
    "- mentioning **ChatGPT** but *not mentioning* programming, refactoring or code;\n",
    "- no retweets;\n",
    "- written in english;\n",
    "- from verified authors;\n",
    "- posted between the 12th of January 2023 at 2pm (UK time) and 12th of January 2023 at 3pm (UK time);\n",
    "- 100 results per call to the API;\n",
    "- tweet fields, user fields and place fields as per exercise 2.\n",
    "\n",
    "\n",
    "*Helpful links:*\n",
    "- Take a look at the list of operators [here](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list)\n",
    "- To know more about start and end times parameters [check this page](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a838921",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    {\"value\": '(chatgpt OR \"chat-gpt\") -(programming OR refactoring OR code) -is:retweet lang:en is:verified', \"tag\":\"exercise_4\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b61ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_parameters = {\n",
    "    \"tweet.fields\": \"id,text,author_id,created_at,context_annotations,entities,geo,public_metrics,source\",\n",
    "    \"user.fields\": \"id,name,username,created_at,description,location,verified,public_metrics\",\n",
    "    \"place.fields\": \"id,country,country_code,name,full_name,geo,place_type\",\n",
    "    \"expansions\": \"author_id,geo.place_id\",\n",
    "    \"max_results\": 100,\n",
    "    \"start_time\":\"2023-01-12T14:00:00Z\",\n",
    "    \"end_time\":\"2023-01-12T15:00:00Z\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbee015",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789a7469",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex4 = pd.read_pickle(\"tweets_exercise_4.pkl\")\n",
    "users_ex4 = pd.read_pickle(\"users_exercise_4.pkl\")\n",
    "places_ex4 = pd.read_pickle(\"places_exercise_4.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fb4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c092fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "places_ex4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068a567",
   "metadata": {},
   "source": [
    "05. Check the *id* of the first tweet you collected in the previous exercise (which corresponds to the latest tweet). Change query_parameters dictionary to only collect tweets posted after that one (*hint:* make use of the since_id query parameter)\n",
    "\n",
    "\n",
    "*Helpful links:*\n",
    "- Take a look at the list of operators [here](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#list)\n",
    "- To know more about since_id parameter [check this page](https://developer.twitter.com/en/docs/twitter-api/tweets/search/api-reference/get-tweets-search-recent) or [this page](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/paginate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf307bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7d65e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = [\n",
    "    {\"value\": '(chatgpt OR \"chat-gpt\") -(programming OR refactoring OR code) -is:retweet lang:en is:verified', \"tag\":\"exercise_5\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_parameters = {\n",
    "    \"tweet.fields\": \"id,text,author_id,created_at,context_annotations,entities,geo,public_metrics,source\",\n",
    "    \"user.fields\": \"id,name,username,created_at,description,location,verified,public_metrics\",\n",
    "    \"place.fields\": \"id,country,country_code,name,full_name,geo,place_type\",\n",
    "    \"expansions\": \"author_id,geo.place_id\",\n",
    "    \"max_results\": 100,\n",
    "    \"since_id\":tweets_ex4.iloc[0][\"id\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eec445",
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_process_twitter_data(bearer_token, rules, query_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30712f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_ex5 = pd.read_pickle(\"tweets_exercise_5.pkl\")\n",
    "users_ex5 = pd.read_pickle(\"users_exercise_5.pkl\")\n",
    "places_ex5 = pd.read_pickle(\"places_exercise_5.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42597c95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collect_twitter_data",
   "language": "python",
   "name": "collect_twitter_data"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
