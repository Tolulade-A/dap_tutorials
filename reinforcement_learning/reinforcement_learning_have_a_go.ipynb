{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_have_a_go.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7f574f21971e421bb2e6da15b50d432c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfd1a53b4fe24a988a03a37c3c2e102a",
              "IPY_MODEL_b7ee1cb5e0b84b0cbe81f17a6b2397d7",
              "IPY_MODEL_16c42ec7571b430b9da58b597ed57278",
              "IPY_MODEL_bc962cc495b246fd9b76bfa5bffcc441"
            ],
            "layout": "IPY_MODEL_313302033bf2442ab285ab2c54348195"
          }
        },
        "dfd1a53b4fe24a988a03a37c3c2e102a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_142243a5f1b94a9bb0d936c51529dd81",
            "placeholder": "​",
            "style": "IPY_MODEL_e26302ce4baf47b5bde338a8f106a463",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "b7ee1cb5e0b84b0cbe81f17a6b2397d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_9429fe1fa4b246b78a105c63206609d4",
            "placeholder": "​",
            "style": "IPY_MODEL_e54927eca0c34210aec93f8d361cfe83",
            "value": ""
          }
        },
        "16c42ec7571b430b9da58b597ed57278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_c28a5f80d6ad4d979893020182642bf9",
            "style": "IPY_MODEL_018b85cb211c4f2bad86554c468d37d5",
            "tooltip": ""
          }
        },
        "bc962cc495b246fd9b76bfa5bffcc441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13db53fc56d640378d19e85e421da8dc",
            "placeholder": "​",
            "style": "IPY_MODEL_b662cd926fad48489246c737384230fa",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "313302033bf2442ab285ab2c54348195": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "142243a5f1b94a9bb0d936c51529dd81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26302ce4baf47b5bde338a8f106a463": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9429fe1fa4b246b78a105c63206609d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e54927eca0c34210aec93f8d361cfe83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c28a5f80d6ad4d979893020182642bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "018b85cb211c4f2bad86554c468d37d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "13db53fc56d640378d19e85e421da8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b662cd926fad48489246c737384230fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Welcome to the Reinforcement learning 101 have-a-go tutorial!\n",
        "\n",
        "Today we'll go through an example notebook which trains an agent to land on the moon. We will use a Box 2D environment from the Gym library, as well as the PPO model from Stable Baselines 3. We will need a Hugging face package as well to share our model to the hub.\n",
        "\n",
        "### Steps:\n",
        "\n",
        "1. Getting set up\n",
        "2. Getting familiar with the environment\n",
        "3. Testing the environment\n",
        "4. Build the model\n",
        "5. Train model\n",
        "6. Test model\n",
        "7. Upload it to the hub, and render it\n",
        "\n",
        "Let's have a go!"
      ],
      "metadata": {
        "id": "cbHkRTyCqEuG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV-Kzud8xdia"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra] \n",
        "!pip install gym[box2d] \n",
        "!pip install huggingface_sb3\n",
        "!pip install ale-py==0.7.4 # To overcome an issue with gym (https://github.com/DLR-RM/stable-baselines3/issues/875)\n",
        "!pip install pickle5\n",
        "\n",
        "# Virtual display dependencies\n",
        "!sudo apt-get update\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is what our agent interacting with the environment will look like..."
      ],
      "metadata": {
        "id": "zR8sMaQswAyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example video\n",
        "%%html\n",
        "<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "pV7jClhUx68Q",
        "outputId": "ce9566c4-f9b3-4f46-e6aa-c9d7fbcfd2c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<video controls autoplay><source src=\"https://huggingface.co/ThomasSimonini/ppo-LunarLander-v2/resolve/main/replay.mp4\" type=\"video/mp4\"></video>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "import gym \n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv #wrapper that goes around our environment that allows to create a dummy vectorised environment  (argument of some algorithms)\n",
        "from stable_baselines3.common.evaluation import evaluate_policy #test out our model\n",
        "from stable_baselines3.common.env_util import make_vec_env\n",
        "\n",
        "from huggingface_sb3 import load_from_hub, package_to_hub, push_to_hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "#import numpy as np\n",
        "#import matplotlib.pyplot as plt\n",
        "#from IPython import display as ipythondisplay"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "njiZCNdqx7n8",
        "outputId": "5370265a-c04b-4b92-d203-b571506b8dcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-715a46c60e53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import dependencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDummyVecEnv\u001b[0m \u001b[0;31m#wrapper that goes around our environment that allows to create a dummy vectorised environment  (argument of some algorithms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluate_policy\u001b[0m \u001b[0;31m#test out our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see with `Observation Space Shape (8,)` that the observation is a vector of size 8, where each value contains different information about the lander:\n",
        "- Horizontal pad coordinate (x)\n",
        "- Vertical pad coordinate (y)\n",
        "- Horizontal speed (x)\n",
        "- Vertical speed (y)\n",
        "- Angle\n",
        "- Angular speed\n",
        "- If the left leg has contact point touched the land\n",
        "- If the right leg has contact point touched the land"
      ],
      "metadata": {
        "id": "4oiiz41qAt8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We create our environment with gym.make(\"<name_of_the_environment>\")\n",
        "environment_name= 'LunarLander-v2'\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "env.reset()\n",
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space Shape\", env.observation_space.shape)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vynENv3yLKT",
        "outputId": "7c1a7ba9-f628-4674-bc8c-5f8815034bfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_____OBSERVATION SPACE_____ \n",
            "\n",
            "Observation Space Shape (8,)\n",
            "Sample observation [ 0.18261679  0.04823878 -0.61862314  0.00383941 -0.981477    2.1404572\n",
            "  0.00590046  1.1117045 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The action space (the set of possible actions the agent can take) is discrete with 4 actions available 🎮: \n",
        "\n",
        "- Do nothing,\n",
        "- Fire left orientation engine,\n",
        "- Fire the main engine,\n",
        "- Fire right orientation engine.\n",
        "\n",
        "Reward function (the function that will gives a reward at each timestep) 💰:\n",
        "\n",
        "- Moving from the top of the screen to the landing pad and zero speed is about 100~140 points.\n",
        "- Firing main engine is -0.3 each frame\n",
        "- Each leg ground contact is +10 points\n",
        "- Episode finishes if the lander crashes (additional - 100 points) or come to rest (+100 points)"
      ],
      "metadata": {
        "id": "Q_nK29tZA7An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the action space\n",
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.n)\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9ylJcQMyzyk",
        "outputId": "afc420d8-2f90-46f7-ab46-df7c7016ecac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " _____ACTION SPACE_____ \n",
            "\n",
            "Action Space Shape 4\n",
            "Action Space Sample 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# within the environment we generated, let's take a bunch of steps to test it out\n",
        "# try to land 10 times\n",
        "episodes = 10\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0 \n",
        "    \n",
        "    while not done:\n",
        "        #env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "env.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Src7rKP0yTiI",
        "outputId": "fbf1b16f-ea5e-42f6-f4bd-5b9aa82d4a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:-349.3061014611998\n",
            "Episode:2 Score:-222.80266070166454\n",
            "Episode:3 Score:-130.50956246096473\n",
            "Episode:4 Score:-127.72743794116559\n",
            "Episode:5 Score:-86.26976025850452\n",
            "Episode:6 Score:-97.81366725380178\n",
            "Episode:7 Score:-426.91490562120674\n",
            "Episode:8 Score:-155.82354952131868\n",
            "Episode:9 Score:-227.1455477807237\n",
            "Episode:10 Score:-200.41219603863527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model"
      ],
      "metadata": {
        "id": "dq9FhUaqz3i4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# build model\n",
        "# Create a vectorised environment\n",
        "env = make_vec_env('LunarLander-v2', n_envs=16) # to create more diverse training experience\n",
        "model = PPO('MlpPolicy', env, verbose= 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epR9SmJ1zqbz",
        "outputId": "f63316e7-0862-47d6-e0c3-154026f5b833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the model"
      ],
      "metadata": {
        "id": "NFpAfo7zwX0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train model - https://stable-baselines3.readthedocs.io/en/master/common/logger.html - how to read output\n",
        "model.learn(total_timesteps=500000)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TolQJqlc0WuS",
        "outputId": "eeaab5b4-90a8-4a22-b317-1c06f22e9db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 94.5     |\n",
            "|    ep_rew_mean     | -182     |\n",
            "| time/              |          |\n",
            "|    fps             | 3704     |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 8        |\n",
            "|    total_timesteps | 32768    |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 96.3        |\n",
            "|    ep_rew_mean          | -143        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1855        |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 35          |\n",
            "|    total_timesteps      | 65536       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010343928 |\n",
            "|    clip_fraction        | 0.0842      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.38       |\n",
            "|    explained_variance   | 0.00391     |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 188         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.00685    |\n",
            "|    value_loss           | 754         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 99.1        |\n",
            "|    ep_rew_mean          | -95.4       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1578        |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 62          |\n",
            "|    total_timesteps      | 98304       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011336107 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | 0.56        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 103         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    value_loss           | 306         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 112         |\n",
            "|    ep_rew_mean          | -68.3       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1455        |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 90          |\n",
            "|    total_timesteps      | 131072      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012618491 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.699       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 65.6        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0217     |\n",
            "|    value_loss           | 149         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 124         |\n",
            "|    ep_rew_mean          | -39         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1385        |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 118         |\n",
            "|    total_timesteps      | 163840      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014516075 |\n",
            "|    clip_fraction        | 0.231       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.24       |\n",
            "|    explained_variance   | 0.812       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 28.6        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0249     |\n",
            "|    value_loss           | 89.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 157         |\n",
            "|    ep_rew_mean          | -27.5       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1335        |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 147         |\n",
            "|    total_timesteps      | 196608      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014897791 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.17       |\n",
            "|    explained_variance   | 0.862       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 21.3        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.024      |\n",
            "|    value_loss           | 59.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 287         |\n",
            "|    ep_rew_mean          | -34.3       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1173        |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 195         |\n",
            "|    total_timesteps      | 229376      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016122289 |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.09       |\n",
            "|    explained_variance   | 0.915       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 12.8        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0219     |\n",
            "|    value_loss           | 42.3        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 415         |\n",
            "|    ep_rew_mean          | -24.7       |\n",
            "| time/                   |             |\n",
            "|    fps                  | 1047        |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 250         |\n",
            "|    total_timesteps      | 262144      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012866387 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.908       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 20.2        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0112     |\n",
            "|    value_loss           | 51.6        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 588        |\n",
            "|    ep_rew_mean          | 3.8        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 947        |\n",
            "|    iterations           | 9          |\n",
            "|    time_elapsed         | 311        |\n",
            "|    total_timesteps      | 294912     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01556696 |\n",
            "|    clip_fraction        | 0.129      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.1       |\n",
            "|    explained_variance   | 0.93       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 19.7       |\n",
            "|    n_updates            | 80         |\n",
            "|    policy_gradient_loss | -0.00841   |\n",
            "|    value_loss           | 37.2       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 709         |\n",
            "|    ep_rew_mean          | 19.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 878         |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 373         |\n",
            "|    total_timesteps      | 327680      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012305951 |\n",
            "|    clip_fraction        | 0.126       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.12       |\n",
            "|    explained_variance   | 0.937       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.81        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00732    |\n",
            "|    value_loss           | 26.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 842         |\n",
            "|    ep_rew_mean          | 55.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 828         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 435         |\n",
            "|    total_timesteps      | 360448      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013253063 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.06       |\n",
            "|    explained_variance   | 0.934       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 3.7         |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00671    |\n",
            "|    value_loss           | 28.2        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 889        |\n",
            "|    ep_rew_mean          | 81.1       |\n",
            "| time/                   |            |\n",
            "|    fps                  | 790        |\n",
            "|    iterations           | 12         |\n",
            "|    time_elapsed         | 497        |\n",
            "|    total_timesteps      | 393216     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01257693 |\n",
            "|    clip_fraction        | 0.117      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.05      |\n",
            "|    explained_variance   | 0.958      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.08       |\n",
            "|    n_updates            | 110        |\n",
            "|    policy_gradient_loss | -0.00751   |\n",
            "|    value_loss           | 14.2       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 938        |\n",
            "|    ep_rew_mean          | 105        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 766        |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 555        |\n",
            "|    total_timesteps      | 425984     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01113146 |\n",
            "|    clip_fraction        | 0.124      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.01      |\n",
            "|    explained_variance   | 0.963      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.27       |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.00614   |\n",
            "|    value_loss           | 10.6       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 932       |\n",
            "|    ep_rew_mean          | 117       |\n",
            "| time/                   |           |\n",
            "|    fps                  | 755       |\n",
            "|    iterations           | 14        |\n",
            "|    time_elapsed         | 607       |\n",
            "|    total_timesteps      | 458752    |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0084348 |\n",
            "|    clip_fraction        | 0.0851    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.979    |\n",
            "|    explained_variance   | 0.961     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.05      |\n",
            "|    n_updates            | 130       |\n",
            "|    policy_gradient_loss | -0.00464  |\n",
            "|    value_loss           | 13.1      |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 940         |\n",
            "|    ep_rew_mean          | 124         |\n",
            "| time/                   |             |\n",
            "|    fps                  | 739         |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 664         |\n",
            "|    total_timesteps      | 491520      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009383261 |\n",
            "|    clip_fraction        | 0.104       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.905      |\n",
            "|    explained_variance   | 0.963       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.2         |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00389    |\n",
            "|    value_loss           | 12.4        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 957          |\n",
            "|    ep_rew_mean          | 134          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 733          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 714          |\n",
            "|    total_timesteps      | 524288       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054303156 |\n",
            "|    clip_fraction        | 0.0591       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.893       |\n",
            "|    explained_variance   | 0.989        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.466        |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00419     |\n",
            "|    value_loss           | 3.12         |\n",
            "------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<stable_baselines3.ppo.ppo.PPO at 0x7fd2ecf2f2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save trained model\n",
        "model_name = \"ppo-LunarLander-v2\"\n",
        "model.save(model_name)"
      ],
      "metadata": {
        "id": "1RosBAzZ40No"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate model"
      ],
      "metadata": {
        "id": "YzO4BAhs10B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new environment for evaluation\n",
        "eval_env = gym.make('LunarLander-v2')\n",
        "\n",
        "# Evaluate the model with 10 evaluation episodes and deterministic=True\n",
        "mean_reward, std_reward =  evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "\n",
        "# Print the results\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1EBS6tZ1q2G",
        "outputId": "b638f486-09e2-4596-ff8b-073dd98cc9c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/stable_baselines3/common/evaluation.py:69: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  UserWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean_reward=249.91 +/- 21.53714682555622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Post to hub"
      ],
      "metadata": {
        "id": "-FtTXsy63yvS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()\n",
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271,
          "referenced_widgets": [
            "7f574f21971e421bb2e6da15b50d432c",
            "dfd1a53b4fe24a988a03a37c3c2e102a",
            "b7ee1cb5e0b84b0cbe81f17a6b2397d7",
            "16c42ec7571b430b9da58b597ed57278",
            "bc962cc495b246fd9b76bfa5bffcc441",
            "313302033bf2442ab285ab2c54348195",
            "142243a5f1b94a9bb0d936c51529dd81",
            "e26302ce4baf47b5bde338a8f106a463",
            "9429fe1fa4b246b78a105c63206609d4",
            "e54927eca0c34210aec93f8d361cfe83",
            "c28a5f80d6ad4d979893020182642bf9",
            "018b85cb211c4f2bad86554c468d37d5",
            "13db53fc56d640378d19e85e421da8dc",
            "b662cd926fad48489246c737384230fa"
          ]
        },
        "id": "5lYvkC0530uA",
        "outputId": "461dd6b5-8195-4422-9f99-4a9f231ce58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the name of the environment\n",
        "env_id = \"LunarLander-v2\"\n",
        "\n",
        "\n",
        "# TODO: Define the model architecture we used\n",
        "model_architecture = \"PPO\"\n",
        "\n",
        "## Define a repo_id\n",
        "## repo_id is the id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance ThomasSimonini/ppo-LunarLander-v2\n",
        "## CHANGE WITH YOUR REPO ID\n",
        "repo_id = \"your-user-name/ppo-LunarLander-v2\"\n",
        "\n",
        "## Define the commit message\n",
        "commit_message = \"Update PPO LunarLander-v2 trained agent\"\n",
        "\n",
        "# Create the evaluation env\n",
        "eval_env = DummyVecEnv([lambda: gym.make(env_id)])\n",
        "\n",
        "\n",
        "# PLACE the package_to_hub function you've just filled here\n",
        "package_to_hub(model=model, # Our trained model\n",
        "               model_name=model_name, # The name of our trained model \n",
        "               model_architecture=model_architecture, # The model architecture we used: in our case PPO\n",
        "               env_id=env_id, # Name of the environment\n",
        "               eval_env=eval_env, # Evaluation Environment\n",
        "               repo_id=repo_id, # id of the model repository from the Hugging Face Hub (repo_id = {organization}/{repo_name} for instance roberta-sgariglia/ppo-LunarLander-v2\n",
        "               commit_message=commit_message)\n"
      ],
      "metadata": {
        "id": "u7dbbZ9K4f2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some boiler plate code to load a pre-trained model from the Hub"
      ],
      "metadata": {
        "id": "2mHBdfn3viKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_sb3 import load_from_hub\n",
        "repo_id = \"\" # The repo_id\n",
        "filename = \"\" # The model filename.zip\n",
        "\n",
        "# When the model was trained on Python 3.8 the pickle protocol is 5\n",
        "# But Python 3.6, 3.7 use protocol 4\n",
        "# In order to get compatibility we need to:\n",
        "# 1. Install pickle5 (we done it at the beginning of the colab)\n",
        "# 2. Create a custom empty object we pass as paramater to PPO.load()\n",
        "custom_objects = {\n",
        "            \"learning_rate\": 0.0,\n",
        "            \"lr_schedule\": lambda _: 0.0,\n",
        "            \"clip_range\": lambda _: 0.0,\n",
        "}\n",
        "\n",
        "checkpoint = load_from_hub(repo_id, filename)\n",
        "model = PPO.load(checkpoint, custom_objects=custom_objects, print_system_info=True)\n",
        "\n",
        "# Evaluate this model\n",
        "eval_env = gym.make(\"LunarLander-v2\")\n",
        "mean_reward, std_reward = evaluate_policy(model, eval_env, n_eval_episodes=10, deterministic=True)\n",
        "print(f\"mean_reward={mean_reward:.2f} +/- {std_reward}\")"
      ],
      "metadata": {
        "id": "70AvWaaJMMpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rendering our agent in a Google Colab setting using the `colabmyrender` package \n"
      ],
      "metadata": {
        "id": "eSrrSASRqCfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "!sudo pip3 install imageio==2.4.1\n",
        "!pip install colabgymrender==1.0.2"
      ],
      "metadata": {
        "id": "I-89MEk9v0m5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from colabgymrender.recorder import Recorder\n",
        "\n",
        "directory = './video'\n",
        "env = Recorder(eval_env, directory)\n",
        "\n",
        "obs = env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "  action, _state = model.predict(obs)\n",
        "  obs, reward, done, info = env.step(action)\n",
        "env.play()"
      ],
      "metadata": {
        "id": "HAOGBZCyv5xo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}